# -*- coding: utf-8 -*-
"""Trabalho06_Tf_IDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x4nww6dJQlA9LxUNeIRT4Bnx2j9vdLwU

Aluna: Vitória Izabel Mendes Pinto

Sua  tarefa  será  gerar  a  matriz  termo-documento  usando  TF-IDF  por meio  da  aplicação  das fórmulas TF-IDF na matriz termo-documento criada com a utilização do algoritmo Bag of Words. Sobre o Corpus que recuperamos anteriormente.
"""

import requests
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd
import math

"""# Site 01

https://www.tableau.com/learn/articles/natural-language-processing-examples
"""

site01 = "https://www.tableau.com/learn/articles/natural-language-processing-examples"
html = requests.get(site01).text
bs4_site01 = BeautifulSoup(html, "html.parser")
 
get = bs4_site01.find_all('p')
text_dir1 = list(get)

text_array1 = []

for text in text_dir1:
    text_array1.append(text.get_text().split(" "))

# Tirando as repetições do site 01
palavras_site01 = []
for i in text_array1:
  for j in i:
    palavras_site01.append(j)

sem_repeticao1 = []
contador = 0

for palavra in palavras_site01:
    if palavra not in sem_repeticao1:
        sem_repeticao1.append(palavra)
        contador += palavras_site01.count(palavra)
        
    contador = 0

"""# Site 02

https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1
"""

site02 = "https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1"
html = requests.get(site02).text
bs4_site02 = BeautifulSoup(html, "html.parser")
 
get = bs4_site02.find_all('p')
text_dir2 = list(get)

text_array2 = []

for text in text_dir2:
    text_array2.append(text.get_text().split(" "))

# Tirando as repetições do site 02
palavras_site02 = []
for i in text_array2:
  for j in i:
    palavras_site02.append(j)

sem_repeticao2 = []
contador = 0

for palavra in palavras_site02:
    if palavra not in sem_repeticao2:
        sem_repeticao2.append(palavra)
        contador += palavras_site02.count(palavra)
    
    contador = 0

"""# Site 03
https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP

"""

site03 = "https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP"
html = requests.get(site03).text
bs4_site03 = BeautifulSoup(html, "html.parser")
 
get = bs4_site03.find_all('p')
text_dir3 = list(get)

text_array3 = []

for text in text_dir3:
    text_array3.append(text.get_text().split(" "))

# Tirando as repetições do site 03
palavras_site03 = []
for i in text_array3:
  for j in i:
    palavras_site03.append(j)

sem_repeticao3 = []
contador = 0

for palavra in palavras_site03:
    if palavra not in sem_repeticao3:
        sem_repeticao3.append(palavra)
        contador += palavras_site03.count(palavra)
    
    contador = 0

"""# Site 04
https://hbr.org/2022/04/the-power-of-natural-language-processing

"""

site04 = "https://hbr.org/2022/04/the-power-of-natural-language-processing"
html = requests.get(site04).text
bs4_site04 = BeautifulSoup(html, "html.parser")
 
get = bs4_site04.find_all('p')
text_dir4 = list(get)

text_array4 = []

for text in text_dir4:
    text_array4.append(text.get_text().split(" "))

# Tirando as repetições do site 04
palavras_site04 = []
for i in text_array4:
  for j in i:
    palavras_site04.append(j)

sem_repeticao4 = []
contador = 0

for palavra in palavras_site04:
    if palavra not in sem_repeticao4:
        sem_repeticao4.append(palavra)
        contador += palavras_site04.count(palavra)
    
    contador = 0

"""# Site 05
https://www.thoughtworks.com/en-br/insights/decoder/n/natural-language-processing
"""

site05 = "https://www.thoughtworks.com/en-br/insights/decoder/n/natural-language-processing"
html = requests.get(site05).text
bs4_site05 = BeautifulSoup(html, "html.parser")
 
get = bs4_site05.find_all('p')
text_dir5 = list(get)

text_array5 = []

for text in text_dir5:
    text_array5.append(text.get_text().split(" "))

# Tirando as repetições do site 05
palavras_site05 = []
for i in text_array5:
  for j in i:
    palavras_site05.append(j)

sem_repeticao5 = []
contador = 0

for palavra in palavras_site05:
    if palavra not in sem_repeticao5:
        sem_repeticao5.append(palavra)
        contador += palavras_site05.count(palavra)
    
    contador = 0

"""União dos vetores

Contagem da Frequencia
"""

# Juntando os lexemas dos sites 01 a 05
todosLexemas = []
todosSites = [sem_repeticao1, sem_repeticao2, sem_repeticao3, sem_repeticao4, sem_repeticao5]

for site in todosSites:
  for palavra in site:

      if palavra not in todosLexemas:
          todosLexemas.append(palavra)

# Vendo a frequência de cada palavra em cada site e adicionando na lista
freq1 = []
freq2 = []
freq3 = []
freq4 = []
freq5 = []


contador = 0

for palavra in todosLexemas:
    contador += palavras_site01.count(palavra)
    freq1.append(contador)
    contador = 0

for palavra in todosLexemas:
    contador += palavras_site02.count(palavra)
    freq2.append(contador)
    contador = 0
  
for palavra in todosLexemas:
    contador += palavras_site03.count(palavra)
    freq3.append(contador)
    contador = 0

for palavra in todosLexemas:
    contador += palavras_site04.count(palavra)
    freq4.append(contador)
    contador = 0

for palavra in todosLexemas:
    contador += palavras_site05.count(palavra)
    freq5.append(contador)
    contador = 0

"""Contagem dos termos"""

termos01 = 0
termos02 = 0
termos03 = 0
termos04 = 0
termos05 = 0

for termo in palavras_site01:
    termos01 += 1
for termo in palavras_site02:
    termos02 += 1
for termo in palavras_site03:
    termos03 += 1
for termo in palavras_site04:
    termos04 += 1
for termo in palavras_site05:
    termos05 += 1

"""Calculo TF"""

tf01 = []
for i in freq1:
      x = freq1[i] / termos01
      tf01.append(round(x, 4))

tf02 = []
for i in freq2:
      x = freq2[i] / termos02
      tf02.append(round(x, 4))

tf03 = []
for i in freq3:
      x = freq3[i] / termos03
      tf03.append(round(x, 4))

tf04 = []
for i in freq4:
      x = freq4[i] / termos04
      tf04.append(round(x, 4))

tf05 = []
for i in freq5:
      x = freq5[i] / termos05
      tf05.append(round(x, 4))

"""Calculo IDF

"""

idf = []
numDocumentos = 5
y = 0

for termo in todosLexemas:
    for site in todosSites:
        if termo in site:
            y += 1
    valor = round(math.log10(numDocumentos/y), 4)
    idf.append(valor)
    y = 0

"""Calculo TF - IDF"""

indice01 = 0
indice02 = 0
indice03 = 0
indice04 = 0
indice05 = 0

tfidf_1 = []
tfidf_2 = []
tfidf_3 = []
tfidf_4 = []
tfidf_5 = []

for lex in todosLexemas:
      resultado = round((tf01[indice01] * idf[indice01]), 4)
      tfidf_1.append(f"{tf01[indice01]} * {idf[indice01]} = {resultado}")
      indice01 += 1

for lex in todosLexemas:
      resultado = round((tf02[indice02] * idf[indice02]), 4)
      tfidf_2.append(f"{tf02[indice02]} * {idf[indice02]} = {resultado}")
      indice02 += 1

for lex in todosLexemas:
      resultado = round((tf03[indice03] * idf[indice03]), 4)
      tfidf_3.append(f"{tf03[indice03]} * {idf[indice03]} = {resultado}")
      indice03 += 1

for lex in todosLexemas:
      resultado = round((tf04[indice04] * idf[indice04]), 4)
      tfidf_4.append(f"{tf04[indice04]} * {idf[indice04]} = {resultado}")
      indice04 += 1
      
for lex in todosLexemas:
      resultado = round((tf05[indice05] * idf[indice05]), 4)
      tfidf_5.append(f"{tf05[indice05]} * {idf[indice05]} = {resultado}")
      indice05 += 1

"""Impressão da Matriz Termo"""

# tamanho máximo de colunas o suficiente para caber todos os lexemas
from google.colab.data_table import DataTable
DataTable.max_columns = 2600 

# cada linha da tabela - um documento
primeiraLinha = pd.Series({todosLexemas[i]: tfidf_1[i] for i in range(len(todosLexemas))})
segundaLinha = pd.Series({todosLexemas[i]: tfidf_2[i] for i in range(len(todosLexemas))})
terceiraLinha = pd.Series({todosLexemas[i]: tfidf_3[i] for i in range(len(todosLexemas))})
quartaLinha = pd.Series({todosLexemas[i]: tfidf_4[i] for i in range(len(todosLexemas))})
quintaLinha = pd.Series({todosLexemas[i]: tfidf_5[i] for i in range(len(todosLexemas))})

df = pd.DataFrame([primeiraLinha, segundaLinha, terceiraLinha, quartaLinha, quintaLinha])
df.index = np.arange(1, len(df) + 1)
df.index.names = ['DOCUMENTOS']
df